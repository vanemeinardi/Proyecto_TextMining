{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTibJNUFIlmf"
   },
   "source": [
    "## Características para modelos de aprendizaje automatico para comunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9883,
     "status": "ok",
     "timestamp": 1734464463364,
     "user": {
      "displayName": "Vanesa Beatriz Meinardi",
      "userId": "05011540024275555334"
     },
     "user_tz": 180
    },
    "id": "NFJm8kDRIlmn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UbXEWZ-QIlmq",
    "outputId": "fb4c8528-1947-4e89-bde2-b87c9a739eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El directorio de trabajo actual es: g:\\Unidades compartidas\\Rocío doctorado\\Proyecto NLP\\Códigos\\Comunidades\n"
     ]
    }
   ],
   "source": [
    "directorio_actual = os.getcwd()\n",
    "print(\"El directorio de trabajo actual es:\", directorio_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wFP4KBP3Ilmr",
    "outputId": "bb5482b9-c2fe-4d9a-9d0f-9ec13be7950d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503340, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comunidades = pd.read_csv('G:/Unidades compartidas/Rocío doctorado/Proyecto NLP/Datos/comunidades.csv')\n",
    "comunidades.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1734464573176,
     "user": {
      "displayName": "Vanesa Beatriz Meinardi",
      "userId": "05011540024275555334"
     },
     "user_tz": 180
    },
    "id": "6HGYTVWAIlms",
    "outputId": "1e03b01f-b1c1-486c-8ac6-d3175cd33c4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'retweet_count', 'full_text', 'posicion', 'user_name',\n",
       "       'user_id', 'mencion', 'retweet', 'user_name_mencion', 'comunidad',\n",
       "       'degree_centrality', 'postura'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comunidades.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1734464575904,
     "user": {
      "displayName": "Vanesa Beatriz Meinardi",
      "userId": "05011540024275555334"
     },
     "user_tz": 180
    },
    "id": "6jRnMI_zIlms",
    "outputId": "43e7859a-0873-474c-aa55-2e67e4f75185"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>postura</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @PTSarg: Contamos con una ventaja que ellos...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>En el fondo lo que les jode es nuestra liberta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @femialborto: A vos que decís #Salvemoslasd...</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @CampAbortoLegal: Diputadxs: ¿Qué significa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @CarrioJovenes: Que no coincidamos en el te...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  postura  retweet_count\n",
       "0  RT @PTSarg: Contamos con una ventaja que ellos...        1             14\n",
       "1  En el fondo lo que les jode es nuestra liberta...        1              0\n",
       "2  RT @femialborto: A vos que decís #Salvemoslasd...        1            308\n",
       "3  RT @CampAbortoLegal: Diputadxs: ¿Qué significa...        1           1369\n",
       "4  RT @CarrioJovenes: Que no coincidamos en el te...        0             16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comunidades_filtradas=comunidades[['full_text', 'postura', 'retweet_count']]\n",
    "comunidades_filtradas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5PCjlvcIlmt"
   },
   "source": [
    "Limpieza de los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 16722,
     "status": "ok",
     "timestamp": 1734464600170,
     "user": {
      "displayName": "Vanesa Beatriz Meinardi",
      "userId": "05011540024275555334"
     },
     "user_tz": 180
    },
    "id": "i6tgesdTIlmv",
    "outputId": "25f5db4e-a4be-41f7-81e3-a67f710645df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_20240\\2013827799.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comunidades_filtradas.loc[:, 'full_text_cleaned'] = comunidades_filtradas['full_text'].apply(clean_tweet)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_20240\\2013827799.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comunidades_filtradas.loc[:, 'Question Mark'] = comunidades_filtradas['full_text'].apply(lambda x: '?' in x or '¿' in x)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_20240\\2013827799.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comunidades_filtradas.loc[:, 'Question Mark Count'] = comunidades_filtradas['full_text'].apply(lambda x: x.count('?') + x.count('¿'))\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_20240\\2013827799.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comunidades_filtradas.loc[:, 'Starts with Question Mark'] = comunidades_filtradas['full_text'].apply(lambda x: x.strip().startswith('¿'))\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_20240\\2013827799.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comunidades_filtradas.loc[:, 'Ends with Mark Count'] = comunidades_filtradas['full_text'].apply(lambda x: x.strip().endswith('?'))\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_20240\\2013827799.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comunidades_filtradas.loc[:, 'Upper Ratio'] = comunidades_filtradas['full_text'].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_20240\\2013827799.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comunidades_filtradas.loc[:, 'Exclamation Mark'] = comunidades_filtradas['full_text'].apply(lambda x: '!' in x or '¡' in x)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_20240\\2013827799.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comunidades_filtradas.loc[:, 'Exclamation Mark Count'] = comunidades_filtradas['full_text'].apply(lambda x: x.count('!') + x.count('¡'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>postura</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>full_text_cleaned</th>\n",
       "      <th>Question Mark</th>\n",
       "      <th>Question Mark Count</th>\n",
       "      <th>Starts with Question Mark</th>\n",
       "      <th>Ends with Mark Count</th>\n",
       "      <th>Upper Ratio</th>\n",
       "      <th>Exclamation Mark</th>\n",
       "      <th>Exclamation Mark Count</th>\n",
       "      <th>Ellipsis Occurrence</th>\n",
       "      <th>Hashtag Presence</th>\n",
       "      <th>Text Length</th>\n",
       "      <th>URL Count</th>\n",
       "      <th>Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @PTSarg: Contamos con una ventaja que ellos...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Contamos con una ventaja que ellos no tienen: ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>En el fondo lo que les jode es nuestra liberta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>En el fondo lo que les jode es nuestra liberta...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @femialborto: A vos que decís #Salvemoslasd...</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "      <td>A vos que decís #Salvemoslasdosvidas te pido q...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @CampAbortoLegal: Diputadxs: ¿Qué significa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1369</td>\n",
       "      <td>Diputadxs: ¿Qué significa para ustedes una muj...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @CarrioJovenes: Que no coincidamos en el te...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Que no coincidamos en el tema del aborto con  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503335</th>\n",
       "      <td>RT @NoAlAborto19: @danielscioli me bloqueo por...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>me bloqueo porque le duele la verdad. En sus c...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503336</th>\n",
       "      <td>RT @unidadprovida: “Hoy nuestra deuda es con l...</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>“Hoy nuestra deuda es con la mujeres más pobre...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503337</th>\n",
       "      <td>RT @lasmarias1234: #ArgentinaEsProvida\" #NoAlA...</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>#ArgentinaEsProvida\" #NoAlAbortoEnArgentina #S...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503338</th>\n",
       "      <td>RT @marianoobarrio: Esta inmensa maravilla fue...</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>Esta inmensa maravilla fue sacrificada hoy en ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503339</th>\n",
       "      <td>RT @carolanarbais: @recondogaston @_buscona Ga...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gastón no pierdas el tiempo con estas personas...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503340 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                full_text  postura  \\\n",
       "0       RT @PTSarg: Contamos con una ventaja que ellos...        1   \n",
       "1       En el fondo lo que les jode es nuestra liberta...        1   \n",
       "2       RT @femialborto: A vos que decís #Salvemoslasd...        1   \n",
       "3       RT @CampAbortoLegal: Diputadxs: ¿Qué significa...        1   \n",
       "4       RT @CarrioJovenes: Que no coincidamos en el te...        0   \n",
       "...                                                   ...      ...   \n",
       "503335  RT @NoAlAborto19: @danielscioli me bloqueo por...        0   \n",
       "503336  RT @unidadprovida: “Hoy nuestra deuda es con l...        0   \n",
       "503337  RT @lasmarias1234: #ArgentinaEsProvida\" #NoAlA...        0   \n",
       "503338  RT @marianoobarrio: Esta inmensa maravilla fue...        0   \n",
       "503339  RT @carolanarbais: @recondogaston @_buscona Ga...        0   \n",
       "\n",
       "        retweet_count                                  full_text_cleaned  \\\n",
       "0                  14  Contamos con una ventaja que ellos no tienen: ...   \n",
       "1                   0  En el fondo lo que les jode es nuestra liberta...   \n",
       "2                 308  A vos que decís #Salvemoslasdosvidas te pido q...   \n",
       "3                1369  Diputadxs: ¿Qué significa para ustedes una muj...   \n",
       "4                  16  Que no coincidamos en el tema del aborto con  ...   \n",
       "...               ...                                                ...   \n",
       "503335             10  me bloqueo porque le duele la verdad. En sus c...   \n",
       "503336             36  “Hoy nuestra deuda es con la mujeres más pobre...   \n",
       "503337            115  #ArgentinaEsProvida\" #NoAlAbortoEnArgentina #S...   \n",
       "503338            174  Esta inmensa maravilla fue sacrificada hoy en ...   \n",
       "503339              2  Gastón no pierdas el tiempo con estas personas...   \n",
       "\n",
       "        Question Mark  Question Mark Count  Starts with Question Mark  \\\n",
       "0               False                    0                      False   \n",
       "1               False                    0                      False   \n",
       "2               False                    0                      False   \n",
       "3                True                    2                      False   \n",
       "4               False                    0                      False   \n",
       "...               ...                  ...                        ...   \n",
       "503335          False                    0                      False   \n",
       "503336          False                    0                      False   \n",
       "503337          False                    0                      False   \n",
       "503338          False                    0                      False   \n",
       "503339          False                    0                      False   \n",
       "\n",
       "        Ends with Mark Count  Upper Ratio  Exclamation Mark  \\\n",
       "0                      False     0.071429             False   \n",
       "1                      False     0.114943             False   \n",
       "2                      False     0.028571             False   \n",
       "3                      False     0.135714             False   \n",
       "4                      False     0.050360             False   \n",
       "...                      ...          ...               ...   \n",
       "503335                 False     0.042857             False   \n",
       "503336                 False     0.021429             False   \n",
       "503337                 False     0.107143             False   \n",
       "503338                 False     0.021583             False   \n",
       "503339                 False     0.050000              True   \n",
       "\n",
       "        Exclamation Mark Count  Ellipsis Occurrence  Hashtag Presence  \\\n",
       "0                            0                False              True   \n",
       "1                            0                False              True   \n",
       "2                            0                False              True   \n",
       "3                            0                False              True   \n",
       "4                            0                False             False   \n",
       "...                        ...                  ...               ...   \n",
       "503335                       0                False             False   \n",
       "503336                       0                False             False   \n",
       "503337                       0                False              True   \n",
       "503338                       0                False             False   \n",
       "503339                       1                False              True   \n",
       "\n",
       "        Text Length  URL Count  Quotes  \n",
       "0               116          0   False  \n",
       "1                47          0   False  \n",
       "2               108          0   False  \n",
       "3                71          0   False  \n",
       "4               113          0   False  \n",
       "...             ...        ...     ...  \n",
       "503335          114          0   False  \n",
       "503336          126          0    True  \n",
       "503337           67          0    True  \n",
       "503338          124          0   False  \n",
       "503339           96          0   False  \n",
       "\n",
       "[503340 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Función para limpiar los tweets\n",
    "def clean_tweet(text):\n",
    "    # Eliminar 'RT' al inicio del texto\n",
    "    text = re.sub(r'^RT\\s+', '', text)\n",
    "\n",
    "    # Eliminar menciones (@usuario) y el ':' que pueda seguir\n",
    "    text = re.sub(r'@\\w+:\\s*', '', text)\n",
    "\n",
    "    # Eliminar cualquier otra mención sin el ':' y espacios innecesarios\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    # Eliminar espacios extra generados por las eliminaciones\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Aplicar la función de limpieza al DataFrame\n",
    "comunidades_filtradas.loc[:, 'full_text_cleaned'] = comunidades_filtradas['full_text'].apply(clean_tweet)\n",
    "\n",
    "# Crear nueva columna 'Question Mark': Si hay al menos un signo de interrogación (¿ o ?)\n",
    "comunidades_filtradas.loc[:, 'Question Mark'] = comunidades_filtradas['full_text'].apply(lambda x: '?' in x or '¿' in x)\n",
    "\n",
    "# Crear nueva columna 'Question Mark Count': Contar cuántos signos de interrogación hay (¿ o ?)\n",
    "comunidades_filtradas.loc[:, 'Question Mark Count'] = comunidades_filtradas['full_text'].apply(lambda x: x.count('?') + x.count('¿'))\n",
    "\n",
    "# Crear nueva columna 'Starts with Question Mark': Si el tweet empieza con al menos un signo de interrogación\n",
    "comunidades_filtradas.loc[:, 'Starts with Question Mark'] = comunidades_filtradas['full_text'].apply(lambda x: x.strip().startswith('¿'))\n",
    "\n",
    "# Crear nueva columna 'Ends with Mark Count': Si el tweet termina con al menos un signo de interrogación\n",
    "comunidades_filtradas.loc[:, 'Ends with Mark Count'] = comunidades_filtradas['full_text'].apply(lambda x: x.strip().endswith('?'))\n",
    "\n",
    "# Crear nueva columna 'Upper Ratio': Ratio de letras mayúsculas vs letras totales\n",
    "comunidades_filtradas.loc[:, 'Upper Ratio'] = comunidades_filtradas['full_text'].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
    "\n",
    "# Crear nueva columna 'Exclamation Mark': Si hay al menos un signo de admiración\n",
    "comunidades_filtradas.loc[:, 'Exclamation Mark'] = comunidades_filtradas['full_text'].apply(lambda x: '!' in x or '¡' in x)\n",
    "\n",
    "# Crear nueva columna 'Exclamation Mark Count': Contar cuántos signos de admiración hay\n",
    "comunidades_filtradas.loc[:, 'Exclamation Mark Count'] = comunidades_filtradas['full_text'].apply(lambda x: x.count('!') + x.count('¡'))\n",
    "\n",
    "# Crear nueva columna 'Ellipsis Occurrence': Si hay 3 o más puntos seguidos\n",
    "comunidades_filtradas.loc[:, 'Ellipsis Occurrence'] = comunidades_filtradas['full_text'].apply(lambda x: '...' in x)\n",
    "\n",
    "# Crear nueva columna 'Hashtag Presence': Presencia de hashtags\n",
    "comunidades_filtradas.loc[:, 'Hashtag Presence'] = comunidades_filtradas['full_text'].apply(lambda x: bool(re.search(r'#\\w+', x)))\n",
    "\n",
    "# Crear nueva columna 'Text Length': Largo del texto sin hashtags, URLs, ni menciones de cuentas de Twitter\n",
    "def limpiar_texto(texto):\n",
    "    texto_sin_hashtags_urls = re.sub(r'(@\\w+|http\\S+|#\\w+)', '', texto)  # Remueve hashtags, URLs y menciones\n",
    "    return len(texto_sin_hashtags_urls.strip())\n",
    "\n",
    "comunidades_filtradas.loc[:, 'Text Length'] = comunidades_filtradas['full_text'].apply(limpiar_texto)\n",
    "\n",
    "# Crear nueva columna 'URL Count': Cantidad de URLs en el texto\n",
    "comunidades_filtradas.loc[:, 'URL Count'] = comunidades_filtradas['full_text'].apply(lambda x: len(re.findall(r'http\\S+', x)))\n",
    "\n",
    "# Crear nueva columna 'Quotes': Si hay palabras entre comillas\n",
    "comunidades_filtradas.loc[:, 'Quotes'] = comunidades_filtradas['full_text'].apply(lambda x: bool(re.search(r'[\"“”]', x)))\n",
    "\n",
    "comunidades_filtradas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIYE19fEIlmw"
   },
   "source": [
    "# Eliminamos filas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1734464602465,
     "user": {
      "displayName": "Vanesa Beatriz Meinardi",
      "userId": "05011540024275555334"
     },
     "user_tz": 180
    },
    "id": "_YCYXhaaIlmw",
    "outputId": "3c1d1a16-002c-4674-f755-403b9d191cf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110409"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar duplicados basándote en la columna 'full_text_cleaned' y conservar el primer tweet que aparezca\n",
    "comunidades_filtradas_sin_duplicados = comunidades_filtradas.drop_duplicates(subset='full_text_cleaned', keep='first')\n",
    "\n",
    "# Obtener los índices de las filas sin duplicados\n",
    "indices_sin_duplicados = comunidades_filtradas_sin_duplicados.index\n",
    "len(indices_sin_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1734464604607,
     "user": {
      "displayName": "Vanesa Beatriz Meinardi",
      "userId": "05011540024275555334"
     },
     "user_tz": 180
    },
    "id": "7vdUUXh8Ilmx",
    "outputId": "f9ae768a-dddd-4568-b136-54875563e50d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>postura</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>full_text_cleaned</th>\n",
       "      <th>Question Mark</th>\n",
       "      <th>Question Mark Count</th>\n",
       "      <th>Starts with Question Mark</th>\n",
       "      <th>Ends with Mark Count</th>\n",
       "      <th>Upper Ratio</th>\n",
       "      <th>Exclamation Mark</th>\n",
       "      <th>Exclamation Mark Count</th>\n",
       "      <th>Ellipsis Occurrence</th>\n",
       "      <th>Hashtag Presence</th>\n",
       "      <th>Text Length</th>\n",
       "      <th>URL Count</th>\n",
       "      <th>Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @PTSarg: Contamos con una ventaja que ellos...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Contamos con una ventaja que ellos no tienen: ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>En el fondo lo que les jode es nuestra liberta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>En el fondo lo que les jode es nuestra liberta...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @femialborto: A vos que decís #Salvemoslasd...</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "      <td>A vos que decís #Salvemoslasdosvidas te pido q...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @CampAbortoLegal: Diputadxs: ¿Qué significa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1369</td>\n",
       "      <td>Diputadxs: ¿Qué significa para ustedes una muj...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @CarrioJovenes: Que no coincidamos en el te...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Que no coincidamos en el tema del aborto con  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503323</th>\n",
       "      <td>@clarincom Y una vida terminada #NoAlAborto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y una vida terminada #NoAlAborto</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503328</th>\n",
       "      <td>Ojalá los médicos se organicen y marchen para ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ojalá los médicos se organicen y marchen para ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503333</th>\n",
       "      <td>Debe estar senil ya pobre. Avísenle que el bla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Debe estar senil ya pobre. Avísenle que el bla...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.109848</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503334</th>\n",
       "      <td>RT @todavidavale: La Academia Nacional de Dere...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>La Academia Nacional de Derecho advierte que l...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503339</th>\n",
       "      <td>RT @carolanarbais: @recondogaston @_buscona Ga...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gastón no pierdas el tiempo con estas personas...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110409 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                full_text  postura  \\\n",
       "0       RT @PTSarg: Contamos con una ventaja que ellos...        1   \n",
       "1       En el fondo lo que les jode es nuestra liberta...        1   \n",
       "2       RT @femialborto: A vos que decís #Salvemoslasd...        1   \n",
       "3       RT @CampAbortoLegal: Diputadxs: ¿Qué significa...        1   \n",
       "4       RT @CarrioJovenes: Que no coincidamos en el te...        0   \n",
       "...                                                   ...      ...   \n",
       "503323        @clarincom Y una vida terminada #NoAlAborto        0   \n",
       "503328  Ojalá los médicos se organicen y marchen para ...        0   \n",
       "503333  Debe estar senil ya pobre. Avísenle que el bla...        0   \n",
       "503334  RT @todavidavale: La Academia Nacional de Dere...        0   \n",
       "503339  RT @carolanarbais: @recondogaston @_buscona Ga...        0   \n",
       "\n",
       "        retweet_count                                  full_text_cleaned  \\\n",
       "0                  14  Contamos con una ventaja que ellos no tienen: ...   \n",
       "1                   0  En el fondo lo que les jode es nuestra liberta...   \n",
       "2                 308  A vos que decís #Salvemoslasdosvidas te pido q...   \n",
       "3                1369  Diputadxs: ¿Qué significa para ustedes una muj...   \n",
       "4                  16  Que no coincidamos en el tema del aborto con  ...   \n",
       "...               ...                                                ...   \n",
       "503323              0                   Y una vida terminada #NoAlAborto   \n",
       "503328              0  Ojalá los médicos se organicen y marchen para ...   \n",
       "503333              0  Debe estar senil ya pobre. Avísenle que el bla...   \n",
       "503334              2  La Academia Nacional de Derecho advierte que l...   \n",
       "503339              2  Gastón no pierdas el tiempo con estas personas...   \n",
       "\n",
       "        Question Mark  Question Mark Count  Starts with Question Mark  \\\n",
       "0               False                    0                      False   \n",
       "1               False                    0                      False   \n",
       "2               False                    0                      False   \n",
       "3                True                    2                      False   \n",
       "4               False                    0                      False   \n",
       "...               ...                  ...                        ...   \n",
       "503323          False                    0                      False   \n",
       "503328          False                    0                      False   \n",
       "503333          False                    0                      False   \n",
       "503334          False                    0                      False   \n",
       "503339          False                    0                      False   \n",
       "\n",
       "        Ends with Mark Count  Upper Ratio  Exclamation Mark  \\\n",
       "0                      False     0.071429             False   \n",
       "1                      False     0.114943             False   \n",
       "2                      False     0.028571             False   \n",
       "3                      False     0.135714             False   \n",
       "4                      False     0.050360             False   \n",
       "...                      ...          ...               ...   \n",
       "503323                 False     0.093023             False   \n",
       "503328                 False     0.046875             False   \n",
       "503333                 False     0.109848             False   \n",
       "503334                 False     0.071429             False   \n",
       "503339                 False     0.050000              True   \n",
       "\n",
       "        Exclamation Mark Count  Ellipsis Occurrence  Hashtag Presence  \\\n",
       "0                            0                False              True   \n",
       "1                            0                False              True   \n",
       "2                            0                False              True   \n",
       "3                            0                False              True   \n",
       "4                            0                False             False   \n",
       "...                        ...                  ...               ...   \n",
       "503323                       0                False              True   \n",
       "503328                       0                False              True   \n",
       "503333                       0                False              True   \n",
       "503334                       0                False              True   \n",
       "503339                       1                False              True   \n",
       "\n",
       "        Text Length  URL Count  Quotes  \n",
       "0               116          0   False  \n",
       "1                47          0   False  \n",
       "2               108          0   False  \n",
       "3                71          0   False  \n",
       "4               113          0   False  \n",
       "...             ...        ...     ...  \n",
       "503323           20          0   False  \n",
       "503328          116          0   False  \n",
       "503333           97          1   False  \n",
       "503334           99          0   False  \n",
       "503339           96          0   False  \n",
       "\n",
       "[110409 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar comunidades_filtradas usando los índices sin duplicados\n",
    "comunidades_filtradas_filtrada = comunidades_filtradas.loc[indices_sin_duplicados]\n",
    "\n",
    "comunidades_filtradas_filtrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1734464609120,
     "user": {
      "displayName": "Vanesa Beatriz Meinardi",
      "userId": "05011540024275555334"
     },
     "user_tz": 180
    },
    "id": "_FkDFOOgIlmy",
    "outputId": "4c507266-7223-4f2f-e749-8bf46b32d29a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['full_text', 'postura', 'retweet_count', 'full_text_cleaned',\n",
       "       'Question Mark', 'Question Mark Count', 'Starts with Question Mark',\n",
       "       'Ends with Mark Count', 'Upper Ratio', 'Exclamation Mark',\n",
       "       'Exclamation Mark Count', 'Ellipsis Occurrence', 'Hashtag Presence',\n",
       "       'Text Length', 'URL Count', 'Quotes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comunidades_filtradas_filtrada.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jJvDaDGhIlmz",
    "outputId": "d65bd3f1-f7c2-49a1-9c3c-b00d826fd4a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['postura', 'Question Mark', 'Question Mark Count',\n",
       "       'Starts with Question Mark', 'Ends with Mark Count', 'Upper Ratio',\n",
       "       'Exclamation Mark', 'Exclamation Mark Count', 'Ellipsis Occurrence',\n",
       "       'Hashtag Presence', 'Text Length', 'URL Count', 'Quotes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comunidades_variables_contextuales=comunidades_filtradas_filtrada.drop(['full_text', 'retweet_count', 'full_text_cleaned'], axis=1)\n",
    "comunidades_variables_contextuales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "error",
     "timestamp": 1734464612330,
     "user": {
      "displayName": "Vanesa Beatriz Meinardi",
      "userId": "05011540024275555334"
     },
     "user_tz": 180
    },
    "id": "Vp0w3CBpIlm0",
    "outputId": "6023ffeb-9b6b-4724-a92b-36a7528946d1"
   },
   "outputs": [],
   "source": [
    "\n",
    "comunidades_variables_contextuales.to_csv('G:/Unidades compartidas/Rocío doctorado/Proyecto NLP/Datos/Variables_contextuales_comunidades.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxh30ZIMIlm0"
   },
   "source": [
    "## Obtencion de unigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuGWq0ASIlm1"
   },
   "source": [
    "Preprocesamiento de los textos para utilizarlos como entrada en los modelos de aprendizaje automático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32667,
     "status": "ok",
     "timestamp": 1734464650976,
     "user": {
      "displayName": "Vanesa Beatriz Meinardi",
      "userId": "05011540024275555334"
     },
     "user_tz": 180
    },
    "id": "j1HgH-RYIlm1",
    "outputId": "465b2249-1d57-4fa3-bb78-98bd6565dccf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de tener el paquete de stopwords en español\n",
    "nltk.download('stopwords')\n",
    "df_preproces=pd.DataFrame()\n",
    "# Inicializar el stemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # Eliminar 'RT' al inicio del texto (opcional, si quieres eliminar retweets)\n",
    "    # tweet = re.sub(r'^RT\\s+', '', tweet)\n",
    "\n",
    "    # Eliminar menciones (@usuario), URLs y caracteres no alfabéticos\n",
    "    tweet = re.sub(r'@\\w+|http\\S+', '', tweet)  # Eliminar menciones y URLs\n",
    "\n",
    "    # Reemplazar '#' con una cadena vacía para conservar las palabras de los hashtags\n",
    "    tweet = re.sub(r'#(\\w+)', r'\\1', tweet)  # Eliminar solo el símbolo '#'\n",
    "\n",
    "    # Tokenizar el tweet y aplicar el stemmer\n",
    "    tokens = tweet.split()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Suponiendo que tienes un DataFrame 'df' con una columna 'full_text_cleaned' y una columna 'etiqueta' (la clase)\n",
    "df_preproces['cleaned_tweet'] = comunidades_filtradas_filtrada['full_text_cleaned'].apply(clean_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cont ventaj conviccion fuerz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en fond jod libert novotencontralasmujer abort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a vos dec salvemoslasdosv pid escuch intent ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>signif usted muj novotencontralasmujer abortol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>que coincid tem abort cambi respet admir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503323</th>\n",
       "      <td>y vid termin noalabort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503328</th>\n",
       "      <td>ojal medic organic march grit cuent los vam mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503333</th>\n",
       "      <td>deb senil avisenl blanc verd noalabort noalabo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503334</th>\n",
       "      <td>la academi nacional derech adviert legaliz abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503339</th>\n",
       "      <td>gaston pierd tiemp hay q concentr q salg ley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110409 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cleaned_tweet\n",
       "0                            cont ventaj conviccion fuerz\n",
       "1       en fond jod libert novotencontralasmujer abort...\n",
       "2       a vos dec salvemoslasdosv pid escuch intent ab...\n",
       "3       signif usted muj novotencontralasmujer abortol...\n",
       "4                que coincid tem abort cambi respet admir\n",
       "...                                                   ...\n",
       "503323                             y vid termin noalabort\n",
       "503328  ojal medic organic march grit cuent los vam mi...\n",
       "503333  deb senil avisenl blanc verd noalabort noalabo...\n",
       "503334  la academi nacional derech adviert legaliz abo...\n",
       "503339       gaston pierd tiemp hay q concentr q salg ley\n",
       "\n",
       "[110409 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6mhhEidqIlm2",
    "outputId": "f6575679-d9b0-4a41-d0e7-4957e94cff58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              cont ventaj conviccion fuerz\n",
       "1         en fond jod libert novotencontralasmujer abort...\n",
       "2         a vos dec salvemoslasdosv pid escuch intent ab...\n",
       "3         signif usted muj novotencontralasmujer abortol...\n",
       "4                  que coincid tem abort cambi respet admir\n",
       "                                ...                        \n",
       "503323                               y vid termin noalabort\n",
       "503328    ojal medic organic march grit cuent los vam mi...\n",
       "503333    deb senil avisenl blanc verd noalabort noalabo...\n",
       "503334    la academi nacional derech adviert legaliz abo...\n",
       "503339         gaston pierd tiemp hay q concentr q salg ley\n",
       "Name: cleaned_tweet, Length: 110409, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproces['cleaned_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0F8AledJIlm2"
   },
   "outputs": [],
   "source": [
    "df_preproces['cleaned_tweet']\n",
    "df_preproces['postura']=comunidades_filtradas_filtrada['postura']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "G1pLlsuaIlm2",
    "outputId": "74198ddf-08ff-4012-cae7-86bc6db04c96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cleaned_tweet', 'postura'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproces.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cZa9-qIOIlm2",
    "outputId": "f3556d38-78c3-477f-9aa1-65ce8ef6c3c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "postura\n",
       "1    65155\n",
       "0    45254\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproces['postura'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPxHo8rrIlm3"
   },
   "source": [
    "Modelo de clasificación: el texto se convierte en vectores numéricos usando TF-IDF, y luego se entrena una regresión logística para predecir a qué clase pertenece cada tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ulBPxephIlm3",
    "outputId": "5e149079-99fc-45ef-a10c-9c74bcbad6e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de prueba: 0.85\n",
      "Accuracy en el conjunto de entrenamiento: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "# Separar las características y las etiquetas\n",
    "X = df_preproces['cleaned_tweet']\n",
    "y = df_preproces['postura']  # Asegúrate de que esta columna contiene las clases\n",
    "\n",
    "# Dividir el dataset en conjunto de entrenamiento y de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el pipeline para vectorización y regresión logística\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar el modelo de regresión logística\n",
    "logistic_model = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
    "logistic_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "accuracy_test = logistic_model.score(X_test_vectorized, y_test)\n",
    "print(f'Accuracy en el conjunto de prueba: {accuracy_test:.2f}')\n",
    "\n",
    "# Evaluar el modelo en el conjunto de entrenamiento\n",
    "accuracy_train = logistic_model.score(X_train_vectorized, y_train)\n",
    "print(f'Accuracy en el conjunto de entrenamiento: {accuracy_train:.2f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extraer los coeficientes del modelo y convertirlos en valores absolutos\n",
    "# coefficients = np.abs(logistic_model.coef_).flatten()\n",
    "# vocabulario = tfidf_vectorizer.get_feature_names_out()\n",
    "# # Crear un DataFrame con los términos y sus coeficientes absolutos\n",
    "# coef_df = pd.DataFrame({\n",
    "#     'unigram': vocabulario,\n",
    "#     'AbsCoefficient': coefficients\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 unigram  AbsCoefficient\n",
      "61                abiert        1.322308\n",
      "85                 abord        1.304582\n",
      "104         abortaresmat        1.670981\n",
      "129        abortoalegaly        1.692540\n",
      "133            abortocer        1.796418\n",
      "...                  ...             ...\n",
      "19879             vulner        1.572934\n",
      "20064            yonopar        1.757894\n",
      "20092  yovotoabortolegal        1.868827\n",
      "20099              yovoy        2.380295\n",
      "20176               zurd        2.273082\n",
      "\n",
      "[506 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# # Calcular el percentil 95 de los valores absolutos de los pesos\n",
    "# threshold = np.percentile(np.abs(coefficients), 97.5)\n",
    "# threshold\n",
    "# # Filtrar unigrams cuyo peso sea mayor que el percentil 95 en valor absoluto\n",
    "# significant_unigrams = coef_df[np.abs(coef_df['AbsCoefficient']) >= threshold]\n",
    "# print(significant_unigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las 20 características más importantes:\n",
      "                    unigram  AbsCoefficient\n",
      "13147  noalabortoenargentin       10.486097\n",
      "239            abortolegaly        9.005599\n",
      "1609        argentinaesprov        5.916564\n",
      "181             abortolegal        4.327035\n",
      "13141             noalabort        4.232289\n",
      "12197           mentiraverd        4.004185\n",
      "15760     queelabortosealey        4.003870\n",
      "4777        cuidemoslasdosv        3.965239\n",
      "291           abortoseraley        3.936765\n",
      "15824             quesealey        3.916897\n"
     ]
    }
   ],
   "source": [
    "# top_features = coef_df.sort_values(by='AbsCoefficient', ascending=False)\n",
    "\n",
    "# # Obtener las 10 características con mayor peso\n",
    "# top_features_reg = top_features.head(506)\n",
    "\n",
    "# print(\"Las 20 características más importantes:\")\n",
    "# print(top_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Original con Unigramas de Mayor Peso:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['cleaned_tweet', 'postura', 'noalabortoenargentin', 'abortolegaly',\n",
       "       'argentinaesprov', 'abortolegal', 'noalabort', 'mentiraverd',\n",
       "       'queelabortosealey', 'cuidemoslasdosv',\n",
       "       ...\n",
       "       'recuper', 'prev', 'fren', 'decid', 'jubil', 'austin', 'hijx',\n",
       "       'multipl', 'pav', 'critic'],\n",
       "      dtype='object', length=508)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unigram_df = pd.DataFrame(top_features_reg[['unigram', 'AbsCoefficient']])\n",
    "# # Extraer solo las palabras de top_20_features\n",
    "# top_features_words = unigram_df['unigram'].tolist()\n",
    "# # Crear un nuevo vectorizador usando solo las palabras de top_20_features\n",
    "# custom_vectorizer = TfidfVectorizer(vocabulary=top_features_words)\n",
    "\n",
    "# # Ajustar y transformar el DataFrame original\n",
    "# X_custom = custom_vectorizer.fit_transform(df_preproces['cleaned_tweet'])\n",
    "\n",
    "# # Convertir la matriz resultante a un DataFrame\n",
    "# X_custom_df = pd.DataFrame(X_custom.toarray(), columns=custom_vectorizer.get_feature_names_out(), index=df_preproces.index)\n",
    "\n",
    "# # Agregar las nuevas características al DataFrame original\n",
    "# df_unigramas = pd.concat([df_preproces, X_custom_df], axis=1)\n",
    "\n",
    "# # Mostrar el DataFrame original con las nuevas columnas\n",
    "# print(\"\\nDataFrame Original con Unigramas de Mayor Peso:\")\n",
    "# df_unigramas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comunidades_unigramas=df_unigramas.drop(['cleaned_tweet'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comunidades_unigramas.to_csv('G:/Unidades compartidas/Rocío doctorado/Proyecto NLP/Datos/comunidades_unigramas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_cxUtjOIlm3"
   },
   "source": [
    "Realizamos un análisis Chi-cuadrado para evaluar la relación entre los unigrams (palabras) y la variable objetivo en un conjunto de datos.  Filtramoa los unigrams con p-valores significativos (menores que 0.05) para identificar los unigramAs más relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZyUKlx4zIlm4",
    "outputId": "040487d9-16d2-40b0-a83f-94a7b2f80087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Unigramas por Chi-cuadrado:\n",
      "                    unigram         chi2        p_value\n",
      "13147  noalabortoenargentin  2345.370055   0.000000e+00\n",
      "239            abortolegaly  1527.739043   0.000000e+00\n",
      "1609        argentinaesprov  1492.924898   0.000000e+00\n",
      "13141             noalabort   898.163564  2.460595e-197\n",
      "17436                sialav   795.591805  4.903265e-175\n",
      "16963       salvemoslasdosv   759.921154  2.793858e-167\n",
      "19565                   vid   677.522080  2.310943e-149\n",
      "15824             quesealey   609.594095  1.370990e-134\n",
      "15760     queelabortosealey   418.746851   4.573091e-93\n",
      "181             abortolegal   372.228658   6.122799e-83\n"
     ]
    }
   ],
   "source": [
    "# Calcular Chi-cuadrado\n",
    "chi2_values, p_values = chi2(X_train_vectorized, y_train)\n",
    "vocabulario = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Crear un DataFrame para los resultados de Chi-cuadrado\n",
    "chi2_results = pd.DataFrame({\n",
    "    'unigram': vocabulario,\n",
    "    'chi2': chi2_values,\n",
    "    'p_value': p_values\n",
    "})\n",
    "\n",
    "# Filtrar unigramas con p-valor significativo (ejemplo: p < 0.05)\n",
    "chi2_results = chi2_results[chi2_results['p_value'] < 0.05]\n",
    "\n",
    "# Ordenar por valor Chi-cuadrado\n",
    "chi2_results = chi2_results.sort_values(by='chi2', ascending=False)\n",
    "\n",
    "# Imprimir los resultados de Chi-cuadrado\n",
    "print(\"\\nTop Unigramas por Chi-cuadrado:\")\n",
    "print(chi2_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtdea-1CIlm4"
   },
   "source": [
    "# Agregamos los unigramas más significativos como columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uUJ3I1SSIlm4",
    "outputId": "e83014c0-0353-42a2-ddd5-6905a23b2d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Original con Unigramas de Mayor Peso:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['cleaned_tweet', 'postura', 'noalabortoenargentin', 'abortolegaly',\n",
       "       'argentinaesprov', 'noalabort', 'sialav', 'salvemoslasdosv', 'vid',\n",
       "       'quesealey',\n",
       "       ...\n",
       "       'degener', 'judi', 'almorzandoconml', 'acuerd', 'facultad',\n",
       "       'vamosargentin', 'estoyverd', 'lousteau', 'virg', 'renov'],\n",
       "      dtype='object', length=1283)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extraer solo las palabras de top_20_features\n",
    "top_features_words_chi = chi2_results['unigram'].tolist()\n",
    "# Crear un nuevo vectorizador usando solo las palabras de top_20_features\n",
    "custom_vectorizer = TfidfVectorizer(vocabulary=top_features_words_chi)\n",
    "\n",
    "# Ajustar y transformar el DataFrame original\n",
    "X_custom = custom_vectorizer.fit_transform(df_preproces['cleaned_tweet'])\n",
    "\n",
    "# Convertir la matriz resultante a un DataFrame\n",
    "X_custom_df = pd.DataFrame(X_custom.toarray(), columns=custom_vectorizer.get_feature_names_out(), index=df_preproces.index)\n",
    "\n",
    "# Agregar las nuevas características al DataFrame original\n",
    "df_unigramas_chi = pd.concat([df_preproces, X_custom_df], axis=1)\n",
    "\n",
    "# Mostrar el DataFrame original con las nuevas columnas\n",
    "print(\"\\nDataFrame Original con Unigramas de Mayor Peso:\")\n",
    "df_unigramas_chi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wQtgE6FbIlm5",
    "outputId": "30b8c9d4-f9f5-435b-dcd1-25e350c18090"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['postura', 'noalabortoenargentin', 'abortolegaly', 'argentinaesprov',\n",
       "       'noalabort', 'sialav', 'salvemoslasdosv', 'vid', 'quesealey',\n",
       "       'queelabortosealey',\n",
       "       ...\n",
       "       'degener', 'judi', 'almorzandoconml', 'acuerd', 'facultad',\n",
       "       'vamosargentin', 'estoyverd', 'lousteau', 'virg', 'renov'],\n",
       "      dtype='object', length=1282)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comunidades_unigramas_chi=df_unigramas_chi.drop(['cleaned_tweet'], axis=1)\n",
    "comunidades_unigramas_chi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zbgK2uXIlm5"
   },
   "outputs": [],
   "source": [
    "comunidades_unigramas_chi.to_csv('G:/Unidades compartidas/Rocío doctorado/Proyecto NLP/Datos/Comunidades_unigramas_chi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IEIGFp0IlnT"
   },
   "source": [
    "# ANALISIS DE SENTIMIENTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nVxy1VgQIlnV",
    "outputId": "4c85bd30-d73d-4086-efce-39b645f8d3bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Contamos con una ventaja que ellos no tienen: ...\n",
       "1         En el fondo lo que les jode es nuestra liberta...\n",
       "2         A vos que decís #Salvemoslasdosvidas te pido q...\n",
       "3         Diputadxs: ¿Qué significa para ustedes una muj...\n",
       "4         Que no coincidamos en el tema del aborto con  ...\n",
       "                                ...                        \n",
       "503323                     Y una vida terminada #NoAlAborto\n",
       "503328    Ojalá los médicos se organicen y marchen para ...\n",
       "503333    Debe estar senil ya pobre. Avísenle que el bla...\n",
       "503334    La Academia Nacional de Derecho advierte que l...\n",
       "503339    Gastón no pierdas el tiempo con estas personas...\n",
       "Name: full_text_cleaned, Length: 110409, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comunidades_filtradas_filtrada['full_text_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kbWJxy_0IlnW",
    "outputId": "198287d4-721c-4135-e940-dcc282214a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   full_text_cleaned  cantidad_positivas  \\\n",
      "0  Contamos con una ventaja que ellos no tienen: ...                   2   \n",
      "1  En el fondo lo que les jode es nuestra liberta...                   1   \n",
      "2  A vos que decís #Salvemoslasdosvidas te pido q...                   0   \n",
      "3  Diputadxs: ¿Qué significa para ustedes una muj...                   0   \n",
      "4  Que no coincidamos en el tema del aborto con  ...                   2   \n",
      "\n",
      "   cantidad_negativas  \n",
      "0                   4  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   0  \n",
      "4                   4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Cargar el diccionario NRC en español como un archivo CSV con columnas 'palabra' y 'sentimiento'\n",
    "diccionario = pd.read_csv(\"G:/Unidades compartidas/Rocío doctorado/Proyecto NLP/Datos/lexico_nrc.csv\")\n",
    "\n",
    "# Convertimos a conjuntos de palabras para agilizar la búsqueda\n",
    "palabras_positivas = set(diccionario[diccionario['sentimiento'] == 'positivo']['palabra'])\n",
    "palabras_negativas = set(diccionario[diccionario['sentimiento'] == 'negativo']['palabra'])\n",
    "\n",
    "# Función para preprocesar el texto\n",
    "def limpiar_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'http\\S+', '', texto)  # Eliminar enlaces\n",
    "    texto = re.sub(r'@\\w+', '', texto)  # Eliminar menciones\n",
    "    texto = re.sub(r'#\\w+', '', texto)  # Eliminar hashtags\n",
    "    texto = re.sub(r'[^a-záéíóúñü\\s]', '', texto)  # Eliminar caracteres especiales\n",
    "    return texto.split()\n",
    "\n",
    "# Función para contar palabras positivas y negativas en un tweet\n",
    "def contar_palabras_sentimiento(tweet):\n",
    "    palabras = limpiar_texto(tweet)\n",
    "    positivos = sum(1 for palabra in palabras if palabra in palabras_positivas)\n",
    "    negativos = sum(1 for palabra in palabras if palabra in palabras_negativas)\n",
    "    return pd.Series([positivos, negativos])\n",
    "\n",
    "# Aplicar la función a cada tweet y crear las nuevas columnas en el DataFrame\n",
    "comunidades_filtradas_filtrada[['cantidad_positivas', 'cantidad_negativas']] = comunidades_filtradas['full_text_cleaned'].apply(contar_palabras_sentimiento)\n",
    "\n",
    "# Mostrar el DataFrame para verificar los resultados\n",
    "print(comunidades_filtradas_filtrada[['full_text_cleaned', 'cantidad_positivas', 'cantidad_negativas']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "x1L9cCsdIlnW",
    "outputId": "dfb47c7d-7560-4533-e631-979744ccfbbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         cantidad_positivas  cantidad_negativas\n",
      "postura                                        \n",
      "0                  0.862311            1.444756\n",
      "1                  0.812355            1.211265\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "promedio_por_postura = comunidades_filtradas_filtrada.groupby('postura')[['cantidad_positivas', 'cantidad_negativas']].mean()\n",
    "print(promedio_por_postura)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "eR9_LfeyIlnX",
    "outputId": "43fed55e-6ee5-48e0-e2ac-96064d40c54a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postura\n",
      "0    0.417870\n",
      "1    0.432239\n",
      "Name: razon_positiva_negativa, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "comunidades_filtradas_filtrada['razon_positiva_negativa'] = comunidades_filtradas_filtrada['cantidad_positivas'] / (comunidades_filtradas_filtrada['cantidad_negativas'] + 1)\n",
    "razon_por_postura = comunidades_filtradas_filtrada.groupby('postura')['razon_positiva_negativa'].mean()\n",
    "print(razon_por_postura)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMArSPV1IlnX"
   },
   "source": [
    "Análisis de varianza (ANOVA) para comparar las medias de diferentes grupos de datos. Divide el conjunto de datos en dos categorías (positivas y negativas) basándose en la columna 'postura', y luego calcula la ANOVA por separado para las variables 'cantidad_positivas' y 'cantidad_negativas'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VsOVYF5SIlnY",
    "outputId": "e1bbe125-1d2e-4984-f890-7443b5a54a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postura 0, Shapiro-Wilk cantidad_positivas: ShapiroResult(statistic=0.772774930261004, pvalue=3.063687130552448e-116)\n",
      "Postura 0, Shapiro-Wilk cantidad_negativas: ShapiroResult(statistic=0.8295502634391125, pvalue=1.888844004391049e-108)\n",
      "Postura 1, Shapiro-Wilk cantidad_positivas: ShapiroResult(statistic=0.7708252321498745, pvalue=1.2754359693626166e-125)\n",
      "Postura 1, Shapiro-Wilk cantidad_negativas: ShapiroResult(statistic=0.7853933898557103, pvalue=9.853184021042165e-124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:573: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 45254.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:573: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 65155.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "for nombre, grupo in comunidades_filtradas_filtrada.groupby('postura'):\n",
    "    print(f\"Postura {nombre}, Shapiro-Wilk cantidad_positivas:\", shapiro(grupo['cantidad_positivas']))\n",
    "    print(f\"Postura {nombre}, Shapiro-Wilk cantidad_negativas:\", shapiro(grupo['cantidad_negativas']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "AR-hwi36IlnY",
    "outputId": "2c2162c6-c856-42cb-e490-5f86763db3b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene cantidad_positivas: LeveneResult(statistic=51.417690108217165, pvalue=7.512822050599579e-13)\n",
      "Levene cantidad_negativas: LeveneResult(statistic=306.1445208424068, pvalue=1.869519532618154e-68)\n",
      "Bartlett cantidad_positivas: BartlettResult(statistic=203.20034952558615, pvalue=4.182837396975247e-46)\n",
      "Bartlett cantidad_negativas: BartlettResult(statistic=250.95846586979462, pvalue=1.6050443807963364e-56)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import levene, bartlett\n",
    "grupos_positivos = [grupo['cantidad_positivas'].values for nombre, grupo in comunidades_filtradas_filtrada.groupby('postura')]\n",
    "grupos_negativos = [grupo['cantidad_negativas'].values for nombre, grupo in comunidades_filtradas_filtrada.groupby('postura')]\n",
    "# Levene test (recomendado si los datos no son perfectamente normales)\n",
    "print(\"Levene cantidad_positivas:\", levene(*grupos_positivos))\n",
    "print(\"Levene cantidad_negativas:\", levene(*grupos_negativos))\n",
    "\n",
    "# Bartlett test (para datos normales)\n",
    "print(\"Bartlett cantidad_positivas:\", bartlett(*grupos_positivos))\n",
    "print(\"Bartlett cantidad_negativas:\", bartlett(*grupos_negativos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "twv2pg8iIlnZ",
    "outputId": "3297d873-5e5b-407e-8cd0-b17b07ac99d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA para palabras positivas: F_onewayResult(statistic=64.013460907504, pvalue=1.2475938261619496e-15)\n",
      "ANOVA para palabras negativas: F_onewayResult(statistic=647.6668006348247, pvalue=1.8565518966075216e-142)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "grupos_positivos = [grupo['cantidad_positivas'].values for nombre, grupo in comunidades_filtradas_filtrada.groupby('postura')]\n",
    "grupos_negativos = [grupo['cantidad_negativas'].values for nombre, grupo in comunidades_filtradas_filtrada.groupby('postura')]\n",
    "\n",
    "anova_positivos = f_oneway(*grupos_positivos)\n",
    "anova_negativos = f_oneway(*grupos_negativos)\n",
    "\n",
    "print(\"ANOVA para palabras positivas:\", anova_positivos)\n",
    "print(\"ANOVA para palabras negativas:\", anova_negativos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-kheSN-rIlnZ",
    "outputId": "3e0b29e4-469a-4067-8087-1cd51c45723e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cantidad_positivas</th>\n",
       "      <th>cantidad_negativas</th>\n",
       "      <th>razon_positiva_negativa</th>\n",
       "      <th>postura</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503323</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503328</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503333</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503334</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503339</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110409 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cantidad_positivas  cantidad_negativas  razon_positiva_negativa  \\\n",
       "0                        2                   4                 0.400000   \n",
       "1                        1                   1                 0.500000   \n",
       "2                        0                   1                 0.000000   \n",
       "3                        0                   0                 0.000000   \n",
       "4                        2                   4                 0.400000   \n",
       "...                    ...                 ...                      ...   \n",
       "503323                   0                   0                 0.000000   \n",
       "503328                   0                   2                 0.000000   \n",
       "503333                   2                   2                 0.666667   \n",
       "503334                   1                   2                 0.333333   \n",
       "503339                   0                   2                 0.000000   \n",
       "\n",
       "        postura  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "503323        0  \n",
       "503328        0  \n",
       "503333        0  \n",
       "503334        0  \n",
       "503339        0  \n",
       "\n",
       "[110409 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimientos_comunidad=comunidades_filtradas_filtrada[[ 'cantidad_positivas',\n",
    "       'cantidad_negativas', 'razon_positiva_negativa', 'postura']]\n",
    "sentimientos_comunidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3B7HtVAIlna"
   },
   "outputs": [],
   "source": [
    "sentimientos_comunidad.to_csv('G:/Unidades compartidas/Rocío doctorado/Proyecto NLP/Datos/Analisis_sentimiento_comunidades.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7PG5c9hIlna"
   },
   "source": [
    "# Unimos Todas las características "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-XKKdvpxIlna"
   },
   "outputs": [],
   "source": [
    "comunidades_filtradas_filtrada=comunidades_filtradas_filtrada[['postura', 'retweet_count',\n",
    "       'Question Mark', 'Question Mark Count', 'Starts with Question Mark',\n",
    "       'Ends with Mark Count', 'Upper Ratio', 'Exclamation Mark',\n",
    "       'Exclamation Mark Count', 'Ellipsis Occurrence', 'Hashtag Presence',\n",
    "       'Text Length', 'URL Count', 'Quotes',\n",
    "       'cantidad_positivas', 'cantidad_negativas', 'razon_positiva_negativa']]\n",
    "#df_unigramas_filtrado = df_unigramas.drop(columns=['cleaned_tweet', 'postura'])\n",
    "df_unigramas_chi_filtrado = df_unigramas_chi.drop(columns=['cleaned_tweet', 'postura'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0msKKOuwIlnb",
    "outputId": "cc637a51-98e0-47ae-db66-5c66e881cd4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110409, 523)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Supongamos que 'comunidades_filtradas' y 'df_unigramas' son tus DataFrames\n",
    "# # Asegúrate de que tengan el mismo número de filas\n",
    "# if comunidades_filtradas_filtrada.shape[0] == df_unigramas_filtrado.shape[0]:\n",
    "#     # Concatenar DataFrames\n",
    "#     df_combined = pd.concat([comunidades_filtradas_filtrada, df_unigramas_filtrado], axis=1)\n",
    "# else:\n",
    "#     print(\"Los DataFrames no tienen el mismo número de filas.\")\n",
    "\n",
    "# # Verifica la forma del DataFrame resultante\n",
    "# print(df_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "IjkuGVX4Ilnb",
    "outputId": "6e9f4dd1-60e3-4063-81b0-92b80baa8cfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110409, 1298)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que 'comunidades_filtradas' y 'df_unigramas' son tus DataFrames\n",
    "# Asegúrate de que tengan el mismo número de filas\n",
    "if comunidades_filtradas_filtrada.shape[0] == df_unigramas_chi_filtrado.shape[0]:\n",
    "    # Concatenar DataFrames\n",
    "    df_combined_unigramas_chi = pd.concat([comunidades_filtradas_filtrada, df_unigramas_chi_filtrado], axis=1)\n",
    "else:\n",
    "    print(\"Los DataFrames no tienen el mismo número de filas.\")\n",
    "\n",
    "# Verifica la forma del DataFrame resultante\n",
    "print(df_combined_unigramas_chi.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSWeLO7LIlnc"
   },
   "outputs": [],
   "source": [
    "# df_combined.to_csv('g:/Unidades compartidas/Rocío doctorado/Proyecto NLP/Datos/comunidades_modelos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUCmD47ZIlnc"
   },
   "outputs": [],
   "source": [
    "df_combined_unigramas_chi.to_csv('g:/Unidades compartidas/Rocío doctorado/Proyecto NLP/Datos/comunidades_modelos_chi.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
